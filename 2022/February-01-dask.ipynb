{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P90R-v_Xr6Wd"
      },
      "source": [
        "<font color=\"white\">.</font> | <font color=\"white\">.</font> | <font color=\"white\">.</font>\n",
        "-- | -- | --\n",
        "![RDS](https://library.columbia.edu/content/dam/templates/libraryweb/banners/banner_research-data-services.png) | <h1><font size=\"+6\">Data Club</font></h1> | ![FRC](https://rcfoundations.research.columbia.edu/sites/default/files/logo/foundation.png)\n",
        "\n",
        "---\n",
        "\n",
        "<center><h1> <font color=\"green\">Introduction to Dask</font></h1></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inqZXOaGzQyB"
      },
      "source": [
        "## <font color=\"grey\">Helpful References</font>\n",
        "\n",
        "- <a href=\"https://docs.dask.org/en/latest/why.html\">Why Dask?</a>\n",
        "- <a href=\"https://github.com/dask/dask-tutorial\">dask-tutorial</a>\n",
        "- <a href=\"https://www.manning.com/books/data-science-with-python-and-dask\">Data Science with Python and Dask</a>\n",
        "- <a href=\"https://www.manifold.ai/dask-and-machine-learning-preprocessing-tutorial\">Dask and Machine Learning: Preprocessing Tutorial</a>\n",
        "- <a href=\"https://carpentries-incubator.github.io/lesson-parallel-python/aio/index.html\">Parallel Programming in Python</a>\n",
        "- <a href=\"https://www.youtube.com/watch?v=uGy5gT2vLdI&feature=youtu.be\"> Working with the Python DASK library (video)</a>\n",
        "- <a href=\"https://www.youtube.com/watch?v=t_GRK4L-bnw&feature=youtu.be\">Who uses Dask (video)</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXo0hlzrdZiX"
      },
      "source": [
        "* Note: This notebook borrows extensively from the Nasa Center for Climate Simulation Advanced Software Technology Group Python series.  Check out their full class list <a href=\"https://www.nccs.nasa.gov/nccs-users/user-events/python-classes\">here</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpgUsqOzzQyB",
        "tags": []
      },
      "source": [
        "![fig_dask](https://miro.medium.com/max/1000/1*D6mSsdWECFLn6wJne4VTjg.png)\n",
        "\n",
        "\n",
        "# <font color=\"green\"> What is Dask?</font>\n",
        "\n",
        "- A flexible library for parallel computing in Python \n",
        "- Sympatico with Numpy, Pandas, and Scikit-Learn \n",
        "- A python library to address these problems:\n",
        "     * **Available data does not fit in a single machine's memory.**\n",
        "     * **Data processing task needs to be sped up.**\n",
        "- Orchestrates parallel threads or processes and help speed up processing times.\n",
        "\n",
        "- Dask components and APIs in three layers: \n",
        "    * the scheduler\n",
        "    * low-level APIs\n",
        "    * and high-level APIs.\n",
        "\n",
        "- High-level constructs \n",
        "    * Dask Bags\n",
        "    * Dask DataFrames\n",
        "    * Dask Arrays. \n",
        "    \n",
        "- Highly customized job execution graphs & integration with existing data structures.\n",
        "\n",
        "\n",
        "![fig_layers](http://bicortex.com/bicortex/wp-content/post_content//2019/06/Dask_APIs_Architecture.png)\n",
        "Image Source: bicortex.com\n",
        "\n",
        "\n",
        "![fig_proc](https://www.manifold.ai/hs-fs/hubfs/Blog%20Post%20Illos/ML%20pipelines%20-%20dask%20single%20machine.jpeg?width=600&name=ML%20pipelines%20-%20dask%20single%20machine.jpeg)\n",
        "Image Source: www.manifold.ai\n",
        "\n",
        "\n",
        "**Advantages of Using Dask**\n",
        "\n",
        "- Matively scales NumPy, Pandas, and scikit-learn.\n",
        "- Effective with both medium datasets on a single machine and large datasets on a cluster.\n",
        "- A general framework for parallelizing Python objects.\n",
        "- Low configuration and maintenance overhead.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMlFpreczQyD",
        "tags": []
      },
      "source": [
        "**Recall on Processes and Threads**\n",
        "\n",
        "- A process is an execution of a program. \n",
        "- A thread is a single execution sequence within the process.\n",
        "- A process can contain multiple threads.\n",
        "- Threads perform small tasks, whereas processes are used for more ‘heavyweight’ tasks. \n",
        "\n",
        "| Process | Thread |\n",
        "| --- | --- |\n",
        "| Resouce intensive | Uses fewer resources |\n",
        "| Processes do not share memory with each other. | Threads share memory with each other within the same process. |\n",
        "| Inter process communication is slow. | Inter thread communication is fast. |\n",
        "| Expensive context switching between processes.  | Cheap context switching between threads of the same process. |\n",
        "| If one is blocked, no other can execute until that one unblocks. | While one is blocked and waiting, a second in the same task can run. |\n",
        "| Runs independently & is isolated from other processes | One thread can read, write or change another thread's data |\n",
        "\n",
        "Regular Python can only run one thread at the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvnoiBBPzQyE",
        "tags": []
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IXeBrt-zQyE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!python -m pip install dask[dataframe] --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFSIkMRSzQyF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlWFzeaGvPmc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uktcOPYqt8Cn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "from dask.diagnostics import ProgressBar "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5T1OpTvzQyH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"Pandas version: \", pd.__version__)\n",
        "print(\"Dask   version: \", dask.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KujOL6YVzQyH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from memory_profiler import memory_usage\n",
        "import memory_profiler\n",
        "%load_ext memory_profiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDfV9aJ_zQyH"
      },
      "source": [
        "# <font color=\"green\"> Parallelize Code with `dask.delayed`</font>\n",
        "\n",
        "- A simple way to parallelize the code.\n",
        "- Delay function calls into a task graph with dependencies.\n",
        "- Systems like `dask.dataframe` are built with `dask.delayed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYXsNUpuzQyI"
      },
      "source": [
        "**Simple Example**\n",
        "\n",
        "Consider the following functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGDTJnEBzQyI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aMY0z7NzQyI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyXWyLZWzQyJ"
      },
      "source": [
        "- Use the `dask.delayed` decorator to parallelize the functions `increment` and `add`.\n",
        "- By decorating the functions, we record tasks to be computed later as graphs on parallel hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN3P5jg3zQyJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-yrKTOezQyJ"
      },
      "source": [
        "- Call the delayed version by passing the arguments, as before, but the original function isn't called yet.\n",
        "- A delayed object is made, which keeps track of the function to call and the arguments to pass it.\n",
        "- The `visualize` method (needs the `graphviz` package) represents the operations to be performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHGrFUBOzQyK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpuV0Fp6zQyK"
      },
      "source": [
        "- **total** not physically calculated yet.\n",
        "- Apply the `compute` method to get the answer. \n",
        "- <font color=\"red\">Only now are the data loaded into memory for calculations</font>.\n",
        "- Calculations done using a local thread pool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQZVcgyazQyK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eje7R4xLzQyK"
      },
      "source": [
        "**Using `delayed` in Loops**\n",
        "\n",
        "Consider the sequential code with two for-loops:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86wPLI4fzQyL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY5vX5RizQyL"
      },
      "source": [
        "We can parallelize the above using the `delayed` decorator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd8wrcd9zQyL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi6DrbIszQyL"
      },
      "source": [
        "We can also get the visual representation through a task graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxNNgWQzzQyL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcB1Gev8zQyL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6fgRtyzzQyM"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Use the `delayed` decorator to parallelize the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IXo9-wnzQyM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5fDN1QezQyM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLwdcn-8zQyM",
        "tags": []
      },
      "source": [
        "### Example: Palindromic Words\n",
        "\n",
        "- A palindromic word is a word which characters read the same backward as forward. \n",
        "- Some examples of palindromes are `redivider`, `deified`, `civic`, `radar`, `level`, `rotor`, `kayak`, `reviver`, `racecar`, `madam`, and `refer`.\n",
        "\n",
        "We want to find the number of palindromes from a list of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP3npGkyzQyM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjFz8iNFzQyM"
      },
      "outputs": [],
      "source": [
        "string_list = ['redivider', 'deified', 'civic', 'radar', 'level',\n",
        "               'rotor', 'kayak', 'reviver', 'racecar', 'madam', 'refer',\n",
        "               'Being',  'man', 'not', 'without', 'frequent', 'consciousness',\n",
        "               'that', 'there', 'was', 'some', 'charm', 'this', 'life', 'stood',\n",
        "               'still', 'after', 'looking', 'sky', 'useful', 'instrument',\n",
        "               'regarded', 'appreciative', 'spirit', 'work', 'art',\n",
        "               'superlatively', 'beautiful', 'moment', 'seemed',\n",
        "               'impressed', 'with', 'speaking', 'loneliness', 'scene',\n",
        "               'rather', 'complete', 'abstraction', 'from', 'compass',\n",
        "               'sights', 'sounds', 'man', 'Human', 'shapes', 'interferences',\n",
        "               'troubles', 'joys', 'were', 'they', 'were', 'there',\n",
        "               'seemed', 'shaded', 'hemisphere', 'globe', 'sentient', 'being',\n",
        "               'save', 'himself']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63hR6LUOzQyM"
      },
      "source": [
        "**Using Regular Python**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlCE63MpzQyN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9a_BmGzzQyN"
      },
      "source": [
        "**Using Dask**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVF3uwDZzQyN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSKhfP_EzQyQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6hEy_MOzQyR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT4vG4IlzQyR"
      },
      "source": [
        "The same computations go faster with a Dask Bag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c78p_EZzQyR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqj9NNivzQyR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyn2W7gZzQyR"
      },
      "source": [
        "**<font color=\"red\">Important Lessons</font>**\n",
        "\n",
        "- The `delayed` decorator adds overhead.\n",
        "- No need to use it on fast tasks.\n",
        "- Call `delayed` on the function, not the result.\n",
        "- Break up computations into many pieces. You achieve parallelism by having many delayed calls: Dask will not parallelize the code inside a function decorated with `delayed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwwoPkjozQyR"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Use Dask to parallelize the code below (calculations of `pi`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idAzQuVbzQyR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO3_JfK6zQyS"
      },
      "source": [
        "# <font color=\"red\"> Dask Array</font>\n",
        "\n",
        "- Dask arrays coordinate many Numpy arrays, arranged into chunks within a grid. \n",
        "    - _Parallel_: Uses all of the cores on your computer\n",
        "    - _Larger-than-memory_: Lets you work with data larger than your available memory by breaking arrays into small pieces, operating on those pieces in an order that minimizes the computation's memory footprint, and efficiently streaming data from disk.\n",
        "    - _Blocked Algorithms_: Perform large computations by performing many smaller computations\n",
        "- They support a large subset of the Numpy API.\n",
        "\n",
        "![fig_array](https://miro.medium.com/max/1388/1*JfQnXJ5_R104bPyE8_XhwQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zxtrdpBzQyS"
      },
      "source": [
        "**Create a Dask Array**\n",
        "\n",
        "- Create a 20000x20000 array of random numbers, representing many numpy arrays of size 1000x1000 (or smaller if the array cannot be divided evenly). \n",
        "- There are 400 (20x20) numpy arrays of size 1000x1000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cxg4bhJzQyS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbRDNoL8zQyS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ADYiEgqzQyS"
      },
      "source": [
        "We can use Numpy syntax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2Zw64YAzQyS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5VCHml2zQyS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FzGkcQtzQyS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db0F3piQzQyT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czVF13mFzQyT"
      },
      "source": [
        "Use the **`compute()`** function if you want your result as a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEJbZFEMzQyT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1UuCqgPzQyT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAIcPt1azQyT"
      },
      "source": [
        "**Persist Data in Memory**\n",
        "\n",
        "- If you have the available RAM for your dataset then you can persist data in memory.\n",
        "- This allows future computations to be much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kc5CjcTzQyT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOphDR8JzQyT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-_kN9XbzQyT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mmdy-Ba9zQyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LojoMEG0zQyU"
      },
      "source": [
        "**Numpy against Dask**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv1S05Q_zQyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Atc3RLSxzQyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PMHubJKzQyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGlLiXEdzQyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1XMQKWIzQyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5vN-YCkzQyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUU84nZ7zQyU"
      },
      "source": [
        "Reshapping the chunk size might provide a better performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LVLVubpzQyU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVo4riDczQyV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PFM8Gp9zQyV"
      },
      "source": [
        "**Dask finished faster, but used more total CPU time because Dask was able to transparently parallelize the computation because of the chunk size.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fS_Gl2RzQyV"
      },
      "source": [
        "**<font color=\"red\">Things to Consider</font>**\n",
        "\n",
        "- Use NumPy if your data fits in RAM to avoid Dask's extra layer of complexity.\n",
        "- If you neeed speedups rather than scalability then use Numba for manipulating Numpy arrays.\n",
        "- How to select the chunk size?\n",
        "     - Too small: huge overheads.\n",
        "     - Poorly aligned with data: inefficient reading.\n",
        "     - Optimal chuck size at least 100 Mb.\n",
        "     - Choose a chunk size large enough to reduce the number of chunks that Dask has to manage but small enough that many can fit in memory at once. Dask will often have as many chunks in memory as twice the number of active threads.\n",
        "   \n",
        "\n",
        "**Avoid Oversubscribing Threads**\n",
        "     \n",
        "- By default Dask runs as many concurrent tasks as you have logical cores. \n",
        "- It assumes that each task will consume about one core.\n",
        "- Many array-computing libraries (used in Dask) are themselves multi-threaded, which can cause contention and low performance.\n",
        "- For better performance, we need to explicitly specify the use of one thread:\n",
        "\n",
        "```python\n",
        "   export OMP_NUM_THREADS=1\n",
        "   export MKL_NUM_THREADS=1\n",
        "   export OPENBLAS_NUM_THREADS=1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOR6cmRzQyV"
      },
      "source": [
        "## <font color=\"green\">Memory Profiling</font>\n",
        "\n",
        "- We use the `memory_profiler` package to track memory usage.\n",
        "- It's written in python and monitors processes running python code as well as line by line memory usage. \n",
        "- We use the `memory_usage()` and pass the parameter `interval` to track the frequency of measuring the memory usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrCCcZ7JzQyV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4A7U5twzQyV"
      },
      "source": [
        "You also use Dask profiling options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZElW12KzQyV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z3s4qUyzQyV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV0aKYRQzQyV"
      },
      "source": [
        "# <font color=\"red\"> Dask DataFrames</font>\n",
        "\n",
        "- Use Pandas for tabular data that fit in memory. \n",
        "- Dask DataFrames:\n",
        "     - Coordinate many Pandas DataFrames, partitioned along an index. \n",
        "     - Support a large subset of the Pandas API.\n",
        "     \n",
        "     \n",
        "- One operation on a Dask DataFrame triggers many Pandas operations on the constituent pandas DataFrames.\n",
        "- Speedy Dask Dataframe operations:\n",
        "     - Arithmetic operations \n",
        "     - Common aggregations (`mean`, `min`, `max`, `sum`, etc.)\n",
        "     - Calling `apply`\n",
        "     - Calling `value_counts()`, `drop_duplicates()` or `corr()`\n",
        "     - Filtering with `loc`, `isin`, and row-wise selection\n",
        "\n",
        "![fig_df](https://pythondata.com/wp-content/uploads/2016/11/Screen-Shot-2016-11-24-at-6.52.24-PM-168x300.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFHd6NVhzQyW"
      },
      "source": [
        "### <font color=\"green\"> NYC Flights Dataset</font>\n",
        "\n",
        "Data is specific to flights (in 1990's) out of the three airports in the New York City area."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K_19y5NzQyW"
      },
      "source": [
        "Download the remote data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtS5VxhpzQyW"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "print(\"\\t Downloading NYC dataset...\", end=\"\\n\", flush=True)\n",
        "\n",
        "url = \"https://storage.googleapis.com/dask-tutorial-data/nycflights.tar.gz\"\n",
        "filename, header = urllib.request.urlretrieve(url, \"nycflights.tar.gz\")\n",
        "\n",
        "print(\"\\t Done!\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbdPtxUyzQyW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmMYj-pzzQyW"
      },
      "source": [
        "Extract the `.csv` files from the tar file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0VbSaqozQyW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtBgWy7ZzQyW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8y2yEPGzQyW"
      },
      "source": [
        "Read all the files at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRXgpL7HzQyW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8C6q4HBzQyX"
      },
      "source": [
        "- The representation of the dataframe object contains no data. \n",
        "- `pandas.read_csv` reads in the entire file before inferring datatypes.\n",
        "- `dask.dataframe.read_csv` only reads in a sample from the beginning of the file (or first file). These inferred datatypes are then enforced when reading all partitions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2hBlb7-zQyX"
      },
      "source": [
        "Let's view the first rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZUGlFPnzQyX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEUNbQW9zQyX"
      },
      "source": [
        "Trying to view last rows causes a problem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VHzGGEezQyX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvn0y59vzQyX"
      },
      "source": [
        "- There is an issue with the data types of few columns.\n",
        "- The datatypes inferred in the sample are incorrect.\n",
        "- We can fix it by reading the files again and specify the appropriate data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHteY4PpzQyX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqWcOD43zQyX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf7YJRnrzQyY"
      },
      "source": [
        "### <font color=\"blue\">Perform Operations as with `Pandas DataFrames`</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3jIRzRPzQyY"
      },
      "source": [
        "**Maximum value of a column**:\n",
        "\n",
        "- Let's compute the maximum of the `DepDelay` column.\n",
        "- With `Pandas`, we would loop over each file to find the individual maximums, then find the final maximum over all the individual maxima.\n",
        "- `dask.dataframe` allows us to write pandas-like code that operates on large than memory datasets in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCZ9GSSWzQyY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa0ioSU-zQyY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBQOQRjgzQyY"
      },
      "source": [
        "If we do the same thing in `Pandas`, we will have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABoN1DZwzQyY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe3goXlBzQyY"
      },
      "source": [
        "**Plotting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZEERfnwzQyY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CFJryfHzQyY"
      },
      "source": [
        "**Other Operations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FMZD1SmzQyZ"
      },
      "source": [
        "Number of non-cancelled flights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkZ61lvCzQyZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCmtlUY0zQyZ"
      },
      "source": [
        "Number of non-cancelled flights were taken from each airport:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMD25mplzQyZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SYPYLcPzQyZ"
      },
      "source": [
        "Average departure delay from each airport:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hWH37FCzQyZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG--Lt05zQyZ"
      },
      "source": [
        "Group by destinations and count:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTAqwyJTdZjC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOYfBRrPdZjC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70NkPkM8dZjC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKwH3AHIzQya"
      },
      "source": [
        "**Sharing Intermediate Results**\n",
        "\n",
        "- We sometimes do the same operation more than once. \n",
        "- For most operations, `dask.dataframe` hashes the arguments, allowing duplicate computations to be shared, and only computed once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnky1ECudZjC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z169VchVdZjD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbhQXQ4nzQya"
      },
      "source": [
        "We pass both to a single `compute` call:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72BVN7iodZjD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySrOflB7zQya"
      },
      "source": [
        "The task graphs for both results are merged when calling dask.compute, allowing shared operations to only be done once instead of twice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqW0D345dZjD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GleecaxJzQya"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "- Consider the code below that computes the mean departure delay per airport. \n",
        "- Parallelize the code using Dask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB1lHfWxdZjG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oylWoX5czQyb"
      },
      "source": [
        "### <font color=\"blue\">Example of Machine Learning with Dask</font>\n",
        "\n",
        "Grab columns from the Dask DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W8zrijidZjH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcNyyPY3zQyb"
      },
      "source": [
        "You can query the shape (note delayed # of sample):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BypwevxdZjH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhSrFSH-dZjH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjq-XgR5zQyc"
      },
      "source": [
        "**Basic EDA**\n",
        "\n",
        "We can get descriptive statistics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1w4QhqBdZjI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO_SLFoQzQyc"
      },
      "source": [
        "Perform searches and operations on the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSTFcJdidZjI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2raNhvgnzQyc"
      },
      "source": [
        "**Create the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlzabcu2dZjJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr11rnkdzQyc"
      },
      "outputs": [],
      "source": [
        "#tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_dxN1MGzQyc"
      },
      "source": [
        "**Train the Model**\n",
        "\n",
        "Generate batches of data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw5B7-VidZjJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sj00-JezQyc"
      },
      "source": [
        "We never run of memory while doing the training:\n",
        "\n",
        "```\n",
        "   steps_per_epoch * batch_size = number_of_rows_in_train_data\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwPj9eEmdZjK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ittw1KkzQyd"
      },
      "source": [
        "# <font color=\"red\"> Schedulers</font>\n",
        "\n",
        "- After Dask generates the task graphs, it needs to execute them on parallel hardware. \n",
        "- It is the role of a task scheduler. \n",
        "- There are different task schedulers. Each will consume a task graph and compute the same result, but with different performance characteristics.\n",
        "\n",
        "![schedulers](https://docs.dask.org/en/latest/_images/dask-overview.svg)\n",
        "\n",
        "Image Source: [https://docs.dask.org/en/latest/](https://docs.dask.org/en/latest/)\n",
        "\n",
        "To execute the task graphs there are two types of schedulers:\n",
        "* **Single machine**: Provides basic features on a local process or thread pool. It is simple and cheap to use, although it can only be used on a single machine and does not scale\n",
        "* **Distributed**: Offers more features, but also requires a bit more effort to set up. It can run locally or distributed across a cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYM8--AlzQyd"
      },
      "source": [
        "## <font color=\"blue\"> Single Machine Scheduler</font>\n",
        "\n",
        "Consider the following example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHR8852UdZjK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yctopoFZzQyd"
      },
      "source": [
        "**Single thread**\n",
        "\n",
        "- The single-threaded synchronous scheduler executes all computations in the local thread with no parallelism at all.\n",
        "- It is useful for debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0GN1t_odZjM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NAAX7t8zQyd"
      },
      "source": [
        "**Local threads**\n",
        "\n",
        "Uses `multiprocessing.pool.ThreadPool`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGXz-RWHzQyd"
      },
      "source": [
        "Use all the processors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjadJCNydZjN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_13--UyJzQye"
      },
      "source": [
        "Use some of the processors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bRMaEfJdZjN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTaeHJwszQye"
      },
      "source": [
        "**Local processes**\n",
        "\n",
        "- The multiprocessing scheduler executes computations with a local `multiprocessing.Pool`.\n",
        "- Every task and all of its dependencies are shipped to a local process, executed, and then their result is shipped back to the main process. \n",
        "- Moving data to remote processes and back can introduce performance penalties, particularly when the data being transferred between processes is large. \n",
        "- The multiprocessing scheduler is an excellent choice when workflows are relatively linear, and so does not involve significant inter-task data transfer as well as when inputs and outputs are both small, like filenames and counts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW0LqksszQye"
      },
      "source": [
        "Use all the processors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFr_PLsodZjO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx52670YdZjO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtlEVbHQzQyf"
      },
      "source": [
        "Use some of the processors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4Adb4OvdZjP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnrX_8DMzQyf"
      },
      "source": [
        "## <font color=\"blue\">Distributed Scheduler</font>\n",
        "\n",
        "- The Dask distributed scheduler can either be set up on a cluster or on a personal machine. \n",
        "- It is a centrally managed, distributed, dynamic task scheduler. \n",
        "     - The central dask-scheduler process coordinates the actions of several dask-worker processes spread across multiple machines and the concurrent requests of several clients.\n",
        "     - The scheduler is asynchronous and event-driven, simultaneously responding to requests for computation from multiple clients and tracking the progress of multiple workers.\n",
        "     - The event-driven and asynchronous nature makes it flexible to concurrently handle a variety of workloads coming from multiple users at the same time while also handling a fluid worker population with failures and additions. \n",
        "     - Workers communicate amongst each other for bulk data transfer over TCP.\n",
        "- To set up `dask.distributed`, we need to create client instance by calling `Client` class from `dask.distributed`. \n",
        "- It will internally create a dask scheduler and dask workers. \n",
        "- We will get the **link of the dashboard** where we can analyze tasks running in parallel. \n",
        "- We can pass a number of workers (using the `n_workers` argument) and threads to use per worker process (using the `threads_per_worker` argument).\n",
        "- As soon as you create a client, Dask will automatically start using it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j5EhOzOdZjP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lsOMZKQzQyf"
      },
      "source": [
        "If you aren’t in jupyterlab and using the `dask-labextension`, you can  click the `Dashboard` link to open up the diagnostics dashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZRvd0PGdZjQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBwzLKmTdZjQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8AnFSBEdZjQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqsv40s-zQyg"
      },
      "source": [
        "Shut down the cluster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPtr5c9PdZjS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxQ5OS0czQyg"
      },
      "source": [
        "**<font color=\"red\">Things to Consider</font>**\n",
        "\n",
        "- Each Dask task has overhead (about 1 ms). With a lot tasks this overhead can add up. It is a good idea to give each task more than a few seconds of work.\n",
        "- To better understand how your program is performing, check the [Dask Performance Diagnostics](https://distributed.dask.org/en/latest/diagnosing-performance.html) documentation. You can also view the [video](https://docs.dask.org/en/stable/diagnostics-distributed.html) to find out how to group your work into fewer, more substantial tasks. This might mean that you call lazy operations at once instead of individually. This might also repartitioning your dataframe(s).\n",
        "- A good rule of thumb for choosing number of threads per Dask worker is to choose the square root of the number of cores per node. \n",
        "     - In general more threads per worker are good for a program that spends most of its time in NumPy, SciPy, Numba, etc., and fewer threads per worker are better for simpler programs that spend most of their time in the Python interpreter.\n",
        "- The Dask scheduler runs on a single thread, so assigning it its own node is a waste.\n",
        "- There is no hard limit on Dask scaling. The task overhead though will eventually start to swamp your calculation depending on how long each task takes to compute. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oa5u800zQyg"
      },
      "source": [
        "## <font color=\"blue\"> Example with DataFrame</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00efsy4_zQyg"
      },
      "source": [
        "Build a Pandas DataFrame with 100000 rows and two columns with values selected randomly between 1 and 1000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZlTk7E7dZjU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smf1__SizQyg"
      },
      "source": [
        "Write a function that computes the sum of square for each column of the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-44WNegdZjV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdC2NzzlzQyh"
      },
      "source": [
        "Measure the time it takes to call the function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0xRr7zudZjX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwU_wdbDdZjX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m20tWaB5zQyh"
      },
      "source": [
        "### <font color=\"green\">Parallelize using Dask `Map_Partition`</font>\n",
        "\n",
        "We construct a Dask DataFrame from pandas dataframe using `from_pandas` function and specify the number of partitions (`nparitions`) to break this dataframe into.\n",
        "\n",
        "```python\n",
        "   dd = ddf.from_pandas(df, npartitions=N)\n",
        "```\n",
        "\n",
        "`ddf` is the name you imported Dask Dataframes with, and `npartitions` is an argument telling the Dataframe how you want to partition it.\n",
        "\n",
        "Each partition will run on a different thread, and communication between them will become too costly if there are too many."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQSlEXyFzQyh"
      },
      "source": [
        "We will break into 4 partitions (number of available cores):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4vt72K9dZjZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Z2PlB6zQyh"
      },
      "source": [
        "We will apply `add_squares` method on each of these partitions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-LXGgNVdZjZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsI1aCcJdZjZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBd862WPdZjZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdPRdNpNdZjZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SfJSB8xdZja"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dask_template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}