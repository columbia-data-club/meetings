{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "General Introduction to Pandas and Exploratory Data Analysis (EDA)",
      "provenance": [],
      "authorship_tag": "ABX9TyNOb8vt9y1ILxOhFCK4YgUb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cul-data-club/meetings/blob/main/2022/General_Introduction_to_Pandas_and_Exploratory_Data_Analysis_(EDA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Columbia University Libraries Data Club](https://library.columbia.edu/services/research-data-services/data-club.html) presents:\n",
        "\n",
        "# General Introduction to Pandas and Exploratory Data Analysis (EDA)\n",
        "\n",
        "based on [the work of Isha Shah](https://github.com/cul-data-club/intro-to-data/blob/bdb85366e3648ce52983d2f3bb090095860ae327/Intro_to_Data_in_Python_IS_v3.ipynb) for Columbia University Libraries Data Club\n",
        "\n",
        "[Sign up for the Data Club Mailing list](https://listserv.cuit.columbia.edu/scripts/wa.exe?SUBED1=CUL-DATA-CLUB&A=1)\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives:\n",
        "\n",
        "* Discriminating critically and analyzing responsibly (always) imperfect data\n",
        "* Recognizing and applying data wrangling fundamentals in Pandas\n",
        "* Demonstrating knowledge of resources for finding data\n",
        "* Relating an interest in working with data\n",
        "\n",
        "## Principles of Data Analysis\n",
        "\n",
        "No matter the context in which you're using data, there will always be a few principles you must follow. At the end of the day, you are doing science - you are using empirical observations to test hypotheses (and occasionally, to predict the future based on these hypotheses). Therefore, it is important to follow the same principles that guide scientific inquiry. Your analytical work must be:\n",
        "\n",
        "1. Well-documented\n",
        "1. Conscientious in reducing bias (the same way we randomize trials and only collect the data we need to answer a specific question, we have to make sure our data are clean, examined for potential bias, and are suited to the question we want to answer)\n",
        "1. Reproducible (commenting and code sharing are crucial)\n",
        "1. Responsibly and clearly communicated (you've done all the work, and now it's important to get it out in the world! Communicating the results of data analyses can be very difficult, especially to folks who don't have a background in it. It is your responsibility to do the best you can in stating what your research can and can't answer, and to make sure that any communication about the data comes from the data - don't make unfounded leaps, or allow others to)\n",
        "\n",
        "[Pandas](https://pandas.pydata.org/) is a Python data analysis tool that can help achieve the above.\n"
      ],
      "metadata": {
        "id": "YiugEtznSZHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrRQ805gSVCN"
      },
      "outputs": [],
      "source": [
        "# INITIAL ENVIRONMENT (run only once)\n",
        "\n",
        "# Import packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Let Colab print every output, not just the output of the final command\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Data with Pandas\n",
        "\n",
        "Pandas has several `.read_*()` methods for importing data in different formats, such as `.csv` files, `.pickle` files, `.json` files, `.xlsx` Excel files, and so on. Use control/command-space completion to see all the `.read_*()` methods available and then use it again to see the signature for `.read_csv()`."
      ],
      "metadata": {
        "id": "YCQ-DWmNmcYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use control/command-space completion to see all of the Pandas .read methods \n",
        "# Then do it again to see the signature of Pandas's .read_csv() method:\n",
        "\n",
        "# pd.read"
      ],
      "metadata": {
        "id": "2Hd_n4ZPm5Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can load data straight from the internet. In this case, we will use a subset of the [New York City Taxi and Limousine Commission Trip Record](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) dataset, limited to February 2018."
      ],
      "metadata": {
        "id": "5szARleoqfLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import file from github\n",
        "url = \"https://raw.githubusercontent.com/columbia-university-libraries-data-club/intro-to-data/master/taxi-data.csv\"\n",
        "# \"df\" is the pythonic name for the Pandas DataFrame created by Pandas .read methods.\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rCEbzqGZnUO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chirag Goyal provides [20 crucial Pandas methods for EDA](https://www.analyticsvidhya.com/blog/2021/04/20-must-known-pandas-function-for-exploratory-data-analysis-eda/), and we see the first in use here. Use control/command-space completion to read the documentation about `.head()`. A few other methods and properties let us understand the basic shape (including `.shape`!) of our data."
      ],
      "metadata": {
        "id": "LoWAEMPKrXHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()\n",
        "print('\\n')\n",
        "df.info()\n",
        "print(f'\\ndf.shape: {df.shape}')\n",
        "print(f'df.size: {df.size} (also: rows * columns = {df.shape[0] * df.shape[1]})')\n",
        "print(f'df.ndim: {df.ndim}')"
      ],
      "metadata": {
        "id": "XuUw2xqRq-R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What can we already say about this dataset? Note particularly the `pickup` and `dropoff` columns.\n",
        "\n",
        "On the other hand, the \"Non-Null Count\" indicates that we have no null values, meaning we don't have to use some of the EDA methods, like `.isna()` or `.dropna()`. We should check for duplication, however."
      ],
      "metadata": {
        "id": "oa7apiRywjM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "SRhsnXZBIHoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goyal's other methods and properties include `.sample()`, `.nunique()`, `.index`, `.columns`, `.nlargest()`, `.corr()`, `.dtypes()`, `.memory_usage()`, and `.value_counts()`. This last one we'll use below."
      ],
      "metadata": {
        "id": "btJyxeRfIPFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In the meantime..."
      ],
      "metadata": {
        "id": "VSEvVN6xIpSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import again, but this time parsing dates\n",
        "df_unparsed_dates = df\n",
        "df = pd.read_csv(url, parse_dates=['pickup', 'dropoff'])\n",
        "df.info()"
      ],
      "metadata": {
        "id": "Gxa-sgDQtn2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now compare descriptions of both datasets\n",
        "df_unparsed_dates.describe(include=\"all\", datetime_is_numeric=True)\n",
        "print('\\n')\n",
        "df.describe(include=\"all\", datetime_is_numeric=True)"
      ],
      "metadata": {
        "id": "PY6mSdt8uCR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How is our story about the NYC taxi data changing? What on earth do we make of some of these values?\n",
        "\n",
        "Let's go column by column:\n",
        "\n",
        "1. Pick-up and drop-off dates and times:\n",
        "  - The earliest date in our dataset is 12/31/2008\n",
        "  - The maximum date looks unrealistic (2081?)\n",
        "  - There are nearly 770,000 rows in our dataset, but only about 630,000 unique pickup and dropoff values. Why? Why would there be fewer unique dropoff than pickup date values?\n",
        "1. Passengers and distance:\n",
        "  - What does having zero passengers mean?\n",
        "  - What does having zero distance mean?\n",
        "  - Are these distance values intuitive?\n",
        "1. Fares and payment:\n",
        "  - Why would there be a negative number for a fare or tip?\n",
        "  - What does the column \"payment type\" mean here, and why is it numeric?\n",
        "  - There was a $2,600 cab ride? Was that a mistake?\n",
        "\n",
        "  Let's start isolating our dataset to see what is happening."
      ],
      "metadata": {
        "id": "nWtVjhdy0DNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column of just months\n",
        "df['pickup_month'] = df['pickup'].dt.month\n",
        "\n",
        "# Plot a bar chart by month\n",
        "df.groupby('pickup_month')['pickup'].count().plot(kind='bar')"
      ],
      "metadata": {
        "id": "e_uXDZgbyMm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can we get this information more digestably?\n",
        "df.groupby('pickup_month')['pickup'].count().plot(kind='bar', logy=True)"
      ],
      "metadata": {
        "id": "DgYPWm8G1aMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or, as a table:\n",
        "df['pickup_month'].value_counts()"
      ],
      "metadata": {
        "id": "oda7LLRz1mAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's repeat the above, but with years and not months:\n",
        "df['pickup_year'] = df['pickup'].dt.year\n",
        "df['pickup_year'].value_counts()\n",
        "df.groupby('pickup_year')['pickup'].count().plot(kind='bar', logy=True)"
      ],
      "metadata": {
        "id": "d1xH1gU236TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In short, the data for NYC taxi trips for February 2018 includes data from not February and from not 2018. Time to wrangle."
      ],
      "metadata": {
        "id": "w_63WAv03cd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrangling Data with Pandas to Make Analysis _Possible_\n",
        "\n",
        "Pandas has a peculiar (R-derived) syntax for subsetting the data, which breaks the dataframe into Series (the underlying structure of the DataFrame) that let you use various operators."
      ],
      "metadata": {
        "id": "rOy81VcD3rKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See just the fares from 2081\n",
        "df[df['pickup_year'] == 2081].describe(include=\"all\", datetime_is_numeric=True)\n",
        "\n",
        "# Or from before 2018\n",
        "df[df['pickup_year'] < 2018].describe(include=\"all\", datetime_is_numeric=True)"
      ],
      "metadata": {
        "id": "EhPzTTNh2yKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's just limit the dataset to what we want and not worry about the broken entries\n",
        "\n",
        "df = df[df['pickup_year'] == 2018][df['pickup_month'] == 2]\n",
        "print(df['pickup_year'].unique())\n",
        "print(df['pickup_month'].unique())"
      ],
      "metadata": {
        "id": "ye0PynLb8A_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning for passengers, distance, fare, and payment\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "HP3fMGTyFt_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning passengers\n",
        "df.groupby(\"passengers\")[\"passengers\"].count()\n",
        "\n",
        "# There are a few rides with zero passengers, which seems suspect. Let's drop.\n",
        "# (We could have also investigated what the fare is for these rides:)\n",
        "df[df[\"passengers\"] == 0][\"fare\"].plot(kind = \"hist\")\n",
        "# This shows that many of these do have some nonzero fare - so they're \n",
        "# definitely suspect, and also irrelevant to the questions we want to ask.\n",
        "df = df[df[\"passengers\"] > 0]\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "YEuGfcpSEORC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning for distance, fare, payment\n",
        "df.describe()\n",
        "\n",
        "# Remove trips with 0 distance, after checking how many there are\n",
        "# Here, it might be good to have a dummy variable rather than plotting a\n",
        "# histogram or table with all values\n",
        "df[\"distance\"].groupby([df[\"distance\"] == 0]).count()\n",
        "\n",
        "# Looks like these represent just 7.6k values, let's drop\n",
        "# In another world we could try to interpolate these values using fare,\n",
        "# but these are not relevant to our research question."
      ],
      "metadata": {
        "id": "3GeFBvnSFzuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"distance\"] > 0]\n",
        "df[\"distance\"].describe()"
      ],
      "metadata": {
        "id": "Ly80rm0CFqq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looks like there is in fact at least one trip that had a distance traveled of \n",
        "# 0.01. Is this reasonable? Should we have used a higher cutoff than 0?\n",
        "# Let's calculate in feet!\n",
        "0.01 * 5280 # number of feet in a mile\n",
        "# Ok, does it make sense to have a trip that was only 52 feet long?\n",
        "# One NYC block (north-south) is 264 feet. How many miles is this?\n",
        "264 / 5280\n",
        "# 0.05 miles! Let's make this the new cutoff.\n",
        "df = df[df[\"distance\"] > 0.05]\n",
        "df[\"distance\"].describe()"
      ],
      "metadata": {
        "id": "a2ZXd30ZGIb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the fare and tip fields\n",
        "# Multiple choice - which one of these WILL work?\n",
        "# A - df[\"fare, tip\"].describe()\n",
        "# B - df[\"fare\", \"tip\"].describe()\n",
        "# C - df[[\"fare\", \"tip\"]].describe()\n"
      ],
      "metadata": {
        "id": "1dupvz6QGHib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"fare\", \"tip\"]].describe()"
      ],
      "metadata": {
        "id": "5xcqY3KFGThQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop negative fares since these look like refunds\n",
        "# In a transactions database, why would this not be a good idea?\n",
        "# Should the threshold be higher? What is the base fare for an NYC taxi?\n",
        "\n",
        "df = df[df[\"fare\"] > 2.5]\n",
        "df[\"fare\"].plot(kind = \"hist\", logy=True)"
      ],
      "metadata": {
        "id": "tFzNZRp-GUyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping far-off fares because they do not seem to be representative\n",
        "df = df[df[\"fare\"] < 200]\n",
        "df[\"fare\"].plot(kind = \"hist\", logy=True)"
      ],
      "metadata": {
        "id": "cujL51TjGYza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the fun part: let's ask questions!\n",
        "\n",
        "Let's investigate the potential effects of increasing the number of people in a taxi. Does it affect how likely and how much someone is to tip? Does it relate to how far they travel?\n",
        "I'm nosy, so I also want to know - how much do people generally tip?\n",
        "Are there differences in volume of passengers during different times of day?\n",
        "What about payment type - who is still using cash, and at what time of day? Are they groups?"
      ],
      "metadata": {
        "id": "MfmmYaobGrCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function and applying it to a pandas series\n",
        "def pass_sort(row):\n",
        "  if row['passengers'] > 3:\n",
        "      return 'Four or more'\n",
        "  if row['passengers'] > 1:\n",
        "      return 'Two to three'\n",
        "  if row['passengers'] == 1:\n",
        "      return 'One'\n",
        "\n",
        "df[\"passenger_type\"] = df.apply(lambda row: pass_sort(row), axis = 1)\n",
        "\n",
        "# Use column manipulation to create new columns\n",
        "df[\"tip_pct\"] = df['tip'] / df['fare']\n",
        "df[\"pickup_time\"] = df[\"pickup\"].dt.time\n",
        "df.head()\n",
        "\n",
        "# Reshaping data\n",
        "df_pivot = df.pivot(columns = \"passenger_type\", values = [\"pickup_time\", \"tip_pct\"])"
      ],
      "metadata": {
        "id": "CIzxn9ceGiky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also use transform to add a column (like R mutate)\n",
        "df[\"rec\"] = 1\n",
        "df[\"medtippct\"] = df.groupby(\"rec\")[\"tip_pct\"].transform('median')\n",
        "# Transform must have a grouping variable\n",
        "\n",
        "# And can also use transform and apply to add a column and make a comparison \n",
        "# at the same time\n",
        "df[\"above_medtippct\"] = df[\"tip_pct\"].transform(lambda x: x > x.median())\n",
        "\n",
        "df[[\"tip_pct\", \"medtippct\", \"above_medtippct\"]].head()"
      ],
      "metadata": {
        "id": "3XEvJmZNG120"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collapse to find average pickup time and tip_pct\n",
        "df_pivot[\"tip_pct\"].aggregate(\"median\")\n",
        "df_pivot[\"tip_pct\"].aggregate(\"mean\")"
      ],
      "metadata": {
        "id": "Fl6ROh1SHOYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot[\"tip_pct\"].aggregate(\"mean\").plot(kind = \"bar\")\n"
      ],
      "metadata": {
        "id": "m1yIhci7HVc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize tip percent and distance by passenger number\n",
        "\n",
        "plt.scatter(x = df[\"passengers\"], y = df[\"distance\"])\n",
        "plt.title('Passengers vs distance')\n",
        "plt.xlabel('Passenger number')\n",
        "plt.ylabel('Distance (mi)')\n",
        "plt.show()\n",
        "\n",
        "df.groupby(\"passengers\")[\"distance\"].median().plot(kind = \"bar\")\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(x = df[\"passengers\"], y = df[\"tip_pct\"])\n",
        "plt.show()\n",
        "\n",
        "df.groupby(\"passengers\")[\"tip_pct\"].aggregate(\"median\").plot(kind = \"bar\")\n",
        "plt.show()\n",
        "\n",
        "df.groupby(\"passengers\")[\"tip_pct\"].aggregate(\"mean\").plot(kind = \"bar\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pdNyTfPrHYvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}