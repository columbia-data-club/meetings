{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy+BPui8jwxu4dTQsZb2OR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/columbia-data-club/meetings/blob/main/2023/march_09_python_and_relational_databases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![A blue background with the SQLite logo and the words Data Club on it](https://raw.githubusercontent.com/columbia-data-club/meetings/main/assets/images/data-club-sqlite.png)\n",
        "\n",
        "# Python & Relational Databases\n",
        "\n",
        "March 9, 2023\n",
        "\n",
        "by [Moacir P. de Sá Pereira](https://moacir.com) for the [Columbia Data Club](https://github.com/columbia-data-club/), using data from the [Pokemon-Database](https://github.com/brianr852/Pokemon-Database) on GitHub, forked to [@columbia-data-club/Pokemon-Database](https://github.com/columbia-data-club/Pokemon-Database).\n",
        "\n",
        "This notebook provides an introduction to relational databases in general and to using them with pandas in particular. A basic understanding of Python syntax (such as the one covered in the Data Club’s [Intro to Python video](https://youtu.be/l45rzo4MUHs) should suffice. "
      ],
      "metadata": {
        "id": "Rtt_ZVydvBdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What Is a Relational Database?\n",
        "\n",
        "Simply, but perhaps unhelpfully, a database is a collection of data where the data are structured and grouped into relations. I think it might be easiest to show this relationship using a pretend taxi dataset based on the one we used last week.\n",
        "\n",
        "First, let’s install the [Faker](https://faker.readthedocs.io/en/master/) library, which will let us generate fake data. While we’re here, let’s also install [Pony](https://ponyorm.org), which we’ll be using in the second half of the workshop."
      ],
      "metadata": {
        "id": "6EuEDvOxy6Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install Faker\n",
        "!python -m pip install pony"
      ],
      "metadata": {
        "id": "XbUihAj59Lwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s create a simple dataframe that looks like the one we have been using. We’ll create a pickup time, a dropoff time, a fare, a distance, a number of passengers, and a tip amount."
      ],
      "metadata": {
        "id": "tDnmX8hB9f0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Set the random seeds so we get the same results between us\n",
        "Faker.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Let's define the NYC fare calculator once:\n",
        "#\n",
        "# NYC taxis cost $1.56 per km, have a $2.50 minimum, \n",
        "# and also charge $.50 per minute of waiting.\n",
        "# let's assume an ideal, wait-free speed of 35kph\n",
        "def fare_calculator(distance, duration): # distance in km, duration in min\n",
        "  ideal_duration = distance/(35/60)\n",
        "  wait_charge = 0.5 * (duration - ideal_duration)\n",
        "  if(wait_charge < 0): # wait charge cannot be negative\n",
        "    wait_charge = 0\n",
        "  total_charge = wait_charge + distance * 1.56\n",
        "  if(total_charge > 2.5): # total cannot be below $2.50\n",
        "    return round(total_charge, 2)\n",
        "  return 2.5\n",
        "\n",
        "def build_taxi_data():\n",
        "  pickup_dt = fake.date_time_between(start_date='-15d', end_date='now')\n",
        "  # let's assume trips are 20 minutes long on average, but usually shorter\n",
        "  # (the +1 guarantees no 0 minute trips)\n",
        "  duration_in_minutes = np.random.poisson(19) + 1\n",
        "  dropoff_dt = pickup_dt + dt.timedelta(minutes=duration_in_minutes)\n",
        "  # let's assume taxis travel about 20kph, \n",
        "  # with taxis rarely having an average speed below 10kph\n",
        "  distance_km = (duration_in_minutes / 60) * np.random.normal(loc=20, scale=5)\n",
        "  fare = fare_calculator(distance_km, duration_in_minutes)\n",
        "  # Assume 1.4 passengers on average, but correct for 0s:\n",
        "  random_passenger_count = np.random.poisson(1.4)\n",
        "  passengers = random_passenger_count if random_passenger_count > 0 else 1\n",
        "  return {\n",
        "      'pickup_dt': pickup_dt,\n",
        "      'dropoff_dt': pickup_dt + dt.timedelta(minutes=duration_in_minutes),\n",
        "      'distance_km': distance_km,\n",
        "      # Assume about 1 passenger on average, but no 0s.\n",
        "      'passengers': passengers,\n",
        "      'fare': fare,\n",
        "      # Assume an average tip of 15%\n",
        "      'tip': round(np.random.normal(loc=0.15, scale=0.05) * fare, 2)\n",
        "  }\n",
        "\n",
        "data = [build_taxi_data() for _ in range(100)]\n",
        "df = pd.DataFrame(data)\n",
        "# Let's also add the average speed of the taxi per ride.\n",
        "df[\"speed_kph\"] = df.apply(lambda x: x[\"distance_km\"] / ((x.dropoff_dt - x.pickup_dt).seconds / 3600), axis=1)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "P7dtIaqQy-C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time to add relationality?\n",
        "\n",
        "So far so good, and the dataframe looks a lot like the one we used two weeks ago. But let’s assume this isn’t New York City taxi data, but, rather, the taxi data specifically for Master Splinter’s Taxi Company. Master Splinter has four drivers, and he wants to keep track of the rides each driver gives. Let’s randomly assign each ride to one of his drivers.\n",
        "\n",
        "Can you think of a reason why assigning drivers randomly would not work in the real world?"
      ],
      "metadata": {
        "id": "WUHldAClgQmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to declare the seed in every cell.\n",
        "# Here I'm using a slightly different one for narrative purposes.\n",
        "np.random.seed(46)\n",
        "drivers = [\"Leonardo\", \"Michelangelo\", \"Raphael\", \"Donatello\"]\n",
        "df['driver_id'] = [np.random.choice(drivers) for _ in range(len(df))]"
      ],
      "metadata": {
        "id": "fETsoHeHgPM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Master Splinter doesn’t just run a taxi business. He is also a teacher. When he looks at the aggregated data by driver, he sees that Michelangelo is too busy partying to pick up fares, and when he does, he gets tipped very badly."
      ],
      "metadata": {
        "id": "-BxkO3jgUrA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "earners = df.groupby(\"driver_id\").aggregate(\n",
        "    fare_count=pd.NamedAgg(column=\"pickup_dt\", aggfunc=\"count\"),\n",
        "    distance=pd.NamedAgg(column=\"distance_km\", aggfunc=\"sum\"),\n",
        "    fare_total=pd.NamedAgg(column=\"fare\", aggfunc=\"sum\"),\n",
        "    tip_total=pd.NamedAgg(column=\"tip\", aggfunc=\"sum\"),\n",
        "    avg_speed=pd.NamedAgg(column=\"speed_kph\", aggfunc=\"mean\")\n",
        ")\n",
        "earners[\"tip_rate\"] = earners.apply(\n",
        "    lambda x: x.tip_total/x.fare_total, axis=1\n",
        ")\n",
        "earners"
      ],
      "metadata": {
        "id": "i004W0R6XNQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Master Splinter decides he wants to implement an incentive program for his turtles. He's going to set a baseline tip rate for each driver and see how many of their rides exceed the baseline. Each driver has his own. \n",
        "\n",
        "He’s also worried that Donatello may be driving too carefully and Raphael too recklessly, so he’s going to set a baseline speed for each driver and make sure the driver stays within the range of that speed. \n",
        "\n",
        "Now, every time a driver exceeds his tip rate or keeps his speed to within 0.5 kph of his target, he gets an extra slice of pizza.\n",
        "\n",
        "Let’s keep adding columns to the dataframe…"
      ],
      "metadata": {
        "id": "wb97YeVD9Trj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drivers = {\n",
        "    \"Donatello\": { \"avg_speed\": 18.5, \"tip_rate\": 0.16 },\n",
        "    \"Leonardo\": { \"avg_speed\": 20.5, \"tip_rate\": 0.155 },\n",
        "    \"Michelangelo\": { \"avg_speed\": 18.75, \"tip_rate\": 0.15 },\n",
        "    \"Raphael\": { \"avg_speed\": 20.5, \"tip_rate\": 0.155 }\n",
        "}\n",
        "\n",
        "df[\"driver_target_speed\"] = df.apply(lambda x: drivers[x.driver_id][\"avg_speed\"], axis=1)\n",
        "df[\"driver_target_tip\"] = df.apply(lambda x: drivers[x.driver_id][\"tip_rate\"], axis=1)\n",
        "df[\"driver_within_target_speed\"] = df.apply(lambda x: \n",
        "  (x.speed_kph > (x.driver_target_speed - 0.5) and x.speed_kph < (x.driver_target_speed + 0.5)),\n",
        "  axis=1)\n",
        "df[\"driver_exceeds_target_tip\"] = df.apply(lambda x:\n",
        "  x.tip/x.fare > x.driver_target_tip,\n",
        "  axis=1)\n",
        "\n",
        "pizza_slices = df.groupby(\"driver_id\").aggregate(\n",
        "    safe_speed=pd.NamedAgg(column=\"driver_within_target_speed\", aggfunc=\"sum\"),\n",
        "    good_tip=pd.NamedAgg(column=\"driver_exceeds_target_tip\", aggfunc=\"sum\"),\n",
        ")\n",
        "pizza_slices[\"total_slices\"] = pizza_slices.apply(\n",
        "    lambda x: x.safe_speed + x.good_tip, axis=1\n",
        ")\n",
        "pizza_slices.sort_values(\"total_slices\", ascending=False)"
      ],
      "metadata": {
        "id": "C6PXaLK89zip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just for reference, let’s look at the columns for this dataset."
      ],
      "metadata": {
        "id": "doz94VkxlrYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "Y7aMeFgVj7Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm. Of twelve columns in the dataset, five pertain to the _driver_, not to the actual _trip_ (though `driver_id` is arguably part of the trip… see below).\n",
        "\n",
        "Let’s add one more wrinkle. Say Master Splinter wants to track customer data, too. He asks every customer to leave their name when they take a ride. Furthermore, he wants to send each customer a New Year’s card. Finally, he wants to implement a program where every fifth ride is free."
      ],
      "metadata": {
        "id": "NZlMql6ujp0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Faker.seed(43)\n",
        "def build_customer_data(n):\n",
        "  profile = fake.simple_profile() \n",
        "  return {\n",
        "      \"id\": str(n + 1).zfill(2),\n",
        "      \"name\": profile[\"name\"],\n",
        "      \"address\": profile[\"address\"].replace(\"\\n\", \", \")\n",
        "  }\n",
        "# For illustration purposes, let's assume there are only 10 customers.\n",
        "customers = [ build_customer_data(n) for n in range(10) ]\n",
        "\n",
        "np.random.seed(46)\n",
        "def add_customer_columns(row):\n",
        "  customer = np.random.choice(customers)\n",
        "  row[\"customer_id\"] = customer[\"id\"]\n",
        "  row[\"customer_name\"] = customer[\"name\"]\n",
        "  row[\"customer_address\"] = customer[\"address\"]\n",
        "  return row\n",
        "\n",
        "df = df.apply(add_customer_columns, axis=1)\n",
        "\n",
        "def is_ride_free(row):\n",
        "  index = int(row.name)\n",
        "  is_ride_free = False \n",
        "  if((len(df.iloc[0:index, :][df['customer_name'] == row[\"customer_name\"]]) + 1) % 5 == 0):\n",
        "    is_ride_free = True\n",
        "  return is_ride_free\n",
        "\n",
        "df[\"customer_rides_free\"] = df.apply(is_ride_free, axis=1)"
      ],
      "metadata": {
        "id": "9aZJV9m_DLtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "qgHTGNvsHy5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PLEASE Can We Be Relational?\n",
        "\n",
        "This is beginning to be grotesque. We have sixteen columns in Master Splinter’s dataset of taxi rides, but nine of them deal with the driver and customer. Granted, this is a contrived example, but the issue should be clear: the customer’s address should not belong in the trip data, and it’s probably the case that not even the driver’s target speed or tip should be in the trip data. \n",
        "\n",
        "The trip data should be just for the trips. The data about the drivers we can abstract into a different dataset, while keeping a link to the trips table so we know who drove a specific trip. I already effectively did this by creating the `drivers` dictionary above, which was a second dataset that I smushed into the trips data.\n",
        "\n",
        "The same holds true for the customer data. The `customer` dictionary already has a lot of information in it, but then I smushed it into the trips dataset, too. We can abstract it back out but keep `customer_id` in the trips table to create a link.\n",
        "\n",
        "Trips, drivers, and customers are related to each other, and we can even codify their relationships:\n",
        "\n",
        "* a **trip** has a **driver** and a **customer** (or “belongs to”)\n",
        "* a **driver** has many **trips**\n",
        "* a **customer** has many **trips**\n",
        "\n",
        "We can even formalize the data visually with an [entity relationship diagram](https://www.visual-paradigm.com/guide/data-modeling/what-is-entity-relationship-diagram/):\n",
        "\n",
        "![An entity relationship diagram showing the three tables of the taxi data](https://raw.githubusercontent.com/columbia-data-club/meetings/main/assets/images/master-splinter-taxi-erd.png)\n",
        "\n",
        "Our data now tracks three **entities** in three **tables**. We can see that each entity has some properties, but that the `driver_id` and `customer_id` properties on the trip entity link drivers and customers.\n",
        "\n",
        "We keep data connected to the entity to which it’s connected, and we can then run calculations on the fly to see if a customer rides free or if the driver gets a slice of pizza.\n",
        "\n",
        "And now we have a relational database."
      ],
      "metadata": {
        "id": "_P1ZiQeVH5R1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OK, So What Is a Relational Database?\n",
        "\n",
        "Well, basically the above. Data are separated into tables that are then linked together based on relationships. In this dataset, we have two “one-to-many” (or “has many”) relationships, but it is also possible to have “one-to-one” and “many-to-many” relationships. For example, if each driver had their own car that they always used, there could be a one-to-one relationship there, and properties pertaining to the car (model, year, color) would be stored in a cars table, as opposed to in the drivers table.\n",
        "\n",
        "There are many ways to interact with relational databases, but perhaps the most common is by using the [Structured Query Language](https://en.wikipedia.org/wiki/SQL), or SQL. SQL reads somewhat easily for basic queries, like:\n",
        "\n",
        "```sql\n",
        "SELECT fare, tip FROM trips WHERE passengers > 3 ORDER BY pickup_dt;\n",
        "```\n",
        "\n",
        "This will give us the fare and tip amount of every trip with more than three passengers, sorted by pickup time. \n",
        "\n",
        "Additionally, we can [join tables](https://www.w3schools.com/sql/sql_join.asp) together to leverage the relationality with something like:\n",
        "\n",
        "```sql\n",
        "SELECT COUNT(*)\n",
        "FROM trips\n",
        "INNER JOIN drivers ON trips.driver_id=drivers.id\n",
        "WHERE drivers.id='Leonardo'\n",
        "AND trips.tip / trips.fare > drivers.target_tip;\n",
        "```\n",
        "\n",
        "This will count how many slices of pizza Leonardo gets for exceeding his target tip rate.\n",
        "\n",
        "SQL is expressive and, again, somewhat easy to read, but different database servers implement slightly different syntax. This becomes clear below and paves the way for why, if we’re pythoning with a database, we probably want to get ourselves into using an [object-relational mapper](https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping) as soon as we can, so we can get back to writing regular Python."
      ],
      "metadata": {
        "id": "B1pieJ5agoXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let’s Get Pokémon Data and Create a Database\n",
        "\n",
        "Enough turtles. Let’s import an already existing database into our notebook. Brian Radomski and James Allen, building upon the [Veekun Pokédex](https://veekun.com/dex) put together a 14 table database of Pokémon for a course and then [shared it on GitHub](https://github.com/brianr852/Pokemon-Database). We’ve [forked it](https://github.com/columbia-data-club/Pokemon-Database) for safe-keeping. Radomski and Allen include a few reports in their repository and a MySQL dump of the database. \n",
        "\n",
        "In an ideal world, we would use the [`requests`](https://requests.readthedocs.io/en/latest/) library to download that dump (a database converted into a giant text file with a series of SQL commands that reproduces the database).  Since the dump would be in plain text, we would use the `text` property on the [`Response` object](https://requests.readthedocs.io/en/latest/api/#requests.Response) to read the data in. The code would be straightforward:\n",
        "\n",
        "```py\n",
        "import requests\n",
        "\n",
        "pokemon_database_sql_dump_url = \"https://raw.githubusercontent.com/columbia-data-club/Pokemon-Database/master/Dump20160519-1.sql\"\n",
        "\n",
        "r = requests.get(pokemon_database_sql_dump_url)\n",
        "with open(\"pokemon_database_sql_dump.sql\",'w') as f:\n",
        "  f.write(r.text)\n",
        "```\n",
        "\n",
        "Unfortunately, we cannot use the dump as an actual database without processing it. SQLite can read an `.sql` file and convert it to a database, but it does not look like it’s possible to do that with the Frankenstein SQLite we have in Colab. \n",
        "\n",
        "Outside of Colab, then, I have already done the conversion. It involved using editing the dump (deleting every instance of `NO_AUTO_CREATE_USER,` which was [removed in MySQL 8.0.11](https://dev.mysql.com/doc/relnotes/mysql/8.0/en/news-8-0-11.html)) and then creating a database:\n",
        "\n",
        "```sh\n",
        "mysql.server start\n",
        "mysql -p pokemon < Dump20160519-1.sql\n",
        "```\n",
        "\n",
        "Next, I installed and used the [`mysql-to-sqlite3`](https://pypi.org/project/mysql-to-sqlite3/) Python tool to convert the new MySQL database to a SQLite database:\n",
        "\n",
        "```sh\n",
        "pip install mysql-to-sqlite3\n",
        "mysql2sqlite -u root -p -d pokemon -f pokemon.sqlite\n",
        "```\n",
        "\n",
        "This creates a binary `.sqlite` file. I added it to our [Meetings](https://github.com/columbia-data-club/meetings) repository, and we can download and use that, instead."
      ],
      "metadata": {
        "id": "-smVkpK0y_Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "pokemon_database_url = \"https://github.com/columbia-data-club/meetings/raw/main/assets/data/pokemon.sqlite\"\n",
        "\n",
        "r = requests.get(pokemon_database_url) # create HTTP response object\n",
        "with open(\"pokemon.sqlite\",\"wb\") as f:\n",
        "  f.write(r.content)"
      ],
      "metadata": {
        "id": "5oxYlX4YzEy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can use `sqlite` to point to that database file and create an object that exists inside colab. This means we don’t need a database server and can keep everything local to our Colab sandbox. `SQLite` is available as the [`sql` magic extension](https://github.com/catherinedevlin/ipython-sql) in Colab."
      ],
      "metadata": {
        "id": "63A71bBY2nq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext sql\n",
        "%sql sqlite:///pokemon.sqlite"
      ],
      "metadata": {
        "id": "MrVbQOouzzY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can run some basic SQL queries and make sure the database behaves like we hope it would. Paradoxically, we have a somewhat limited ability to access the metadata for the database. However, we can use the database entity relationship diagram provided by the Radomski and Allen to ground how we can reason about this Pokémon database.\n",
        "\n",
        "![The entity relationship diagram for the Pokémon database](https://raw.githubusercontent.com/columbia-data-club/meetings/main/assets/images/pokemon-db-erd.png)\n",
        "\n",
        "Let’s use the `PRAGMA` command to get information about the `pokemon` table."
      ],
      "metadata": {
        "id": "ombe2MBmTY3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%sql PRAGMA table_info([pokemon]);"
      ],
      "metadata": {
        "id": "5Wsb72u94fd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can run some of the SQL commands the database’s authors provide to query the data, for example, to get a list of pokémon with attack, defense, and hp greater than 100. The resulting object, `strong_pokemon`, can also be converted to a pandas dataframe."
      ],
      "metadata": {
        "id": "uk00Ax93ak9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql strong_pokemon << SELECT pokemon.pok_id, pokemon.pok_name, \n",
        "  base_stats.b_atk, base_stats.b_def, base_stats.b_hp,\n",
        "  base_stats.b_speed, base_stats.b_sp_atk, base_stats.b_sp_def\n",
        "FROM pokemon\n",
        "INNER JOIN base_stats\n",
        "ON pokemon.pok_id = base_stats.pok_id\n",
        "WHERE b_atk > 100 and b_def > 100 and b_hp > 100\n",
        "GROUP BY pokemon.pok_id;"
      ],
      "metadata": {
        "id": "RaB9VpGRaw0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As an ipython-sql result\n",
        "strong_pokemon"
      ],
      "metadata": {
        "id": "MrSKUDc3cXb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As a dataframe\n",
        "strong_pokemon_df = strong_pokemon.DataFrame()\n",
        "strong_pokemon_df"
      ],
      "metadata": {
        "id": "IzYfMfpab_Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object-Relational Mappers\n",
        "\n",
        "Thanks for suffering through that last section. Writing SQL queries (in native SQL like that) is no fun at all, and it takes us out of our programming rhythm. Luckily, [object-relational mappers (ORMs)](https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping) exist. \n",
        "\n",
        "An ORM remaps a database’s structure into the class-based paradigm of object-oriented programming. Because an ERD tracks entities with properties, those entities can be reimagined as classes with properties. The relationships are mapped with some additional syntactic sugar, so instead of remembering SQL syntax and reasoning about the data in the database through whatever specific flavor of database you have, you can use more idiomatic programming structures.\n",
        "\n",
        "There are several ORMs for Python, and some may even be already familiar to you. [SQLAlchemy](https://www.sqlalchemy.org/) seems to be the most popular, but there are smaller, more light-weight ones like [PeeWee](https://docs.peewee-orm.com/en/latest/). ORMs come especially in handy if you are building a web application where the code in your application relies on objects, but the database relies on entities and tables, and the popular web framework [Django](https://www.djangoproject.com/) has its [own ORM](https://docs.djangoproject.com/en/4.1/topics/db/queries/).\n",
        "\n",
        "It's not a perfect comparison, but the crosswalk an ORM provides looks like this:\n",
        "\n",
        "* A **Table** in the database becomes a **Model**, typically represented by a **Class**.\n",
        "* A **Row** in the table becomes a **Model instance**, typically represented by a **Class instance**.\n",
        "* A **Column** in the table becomes a **Attribute** of the model, typically represented by a **Class property**."
      ],
      "metadata": {
        "id": "rRdXb0YQ1UtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enter Pony\n",
        "\n",
        "For the rest of this workshop, we’ll be using [Pony](https://ponyorm.org/) as our ORM. I do not have a lot of experience with Python ORMs, but I like how Pony embraces the more [functional programming](https://en.wikipedia.org//wiki/Functional_programming) side of Python in its use of [generators](https://docs.python.org/3/reference/expressions.html#generator-expressions) and [lambdas](https://docs.python.org/3/reference/expressions.html#lambda).\n",
        "\n",
        "We installed Pony back in the first code cell of this notebook, but now let’s import it."
      ],
      "metadata": {
        "id": "lspR_H5H6dFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pony import orm"
      ],
      "metadata": {
        "id": "ESaFZzvz6cHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Once it’s imported, though, we need to do two things:\n",
        "\n",
        "* Initialize a [`Database`](https://docs.ponyorm.org/api_reference.html#database-class) instance and make the connection (“bind it”) to the database (`pokemon.sqlite`).\n",
        "* Create the mapping that turns the fourteen tables in the Pokémon database into a handful of classes we can work with in Python.\n",
        "\n",
        "To build the mapping, we use [classes](https://www.w3schools.com/python/python_classes.asp) that inherit from Pony’s [`Entity`](https://docs.ponyorm.org/api_reference.html#entity-definition) object. We achieve two goals here: building the main interface for the ORM while also wiring things up correctly in the backend. Let’s start a starter mapping with just the `pokemon` table."
      ],
      "metadata": {
        "id": "IwBUur6z9Wm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a Database instance and bind it to the `pokemon.sqlite` file.\n",
        "starter_db = orm.Database()\n",
        "starter_db.bind(provider='sqlite', filename=\"/content/pokemon.sqlite\", create_db=False)\n",
        "\n",
        "class Pokemon(starter_db.Entity): # Idiomatically, classes tend to be capitalized.\n",
        "  id = orm.PrimaryKey(int, column=\"pok_id\", auto=True) # INT(11)\n",
        "  name = orm.Required(str, column=\"pok_name\") # VARCHAR(79)\n",
        "  height = orm.Optional(int, column=\"pok_height\") # INT(11)\n",
        "  weight = orm.Optional(int, column=\"pok_weight\") # INT(11)\n",
        "  base_experience = orm.Optional(int, column=\"pok_base_experience\") # INT(11)\n",
        "\n",
        "starter_db.generate_mapping(check_tables=True, create_tables=False)"
      ],
      "metadata": {
        "id": "WaB_WFkI8TVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `generate_mapping` method connects the `Pokemon` class to the `pokemon` table in the database, which means now we can do some simple queries to show the syntax in action."
      ],
      "metadata": {
        "id": "nVEjU7voDgYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get all the pokemon step by step to understand the API.\n",
        "all_pokemon_query = orm.select(p for p in Pokemon)\n",
        "type(all_pokemon_query)"
      ],
      "metadata": {
        "id": "J0ZE04XahPHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pony’s [`Query`](https://docs.ponyorm.org/api_reference.html#query-object) object contains the the database query, but to iterate over the results of the query, we have to add list-like syntax that turns the `Query` into a `QueryResult`, which is generally list-like."
      ],
      "metadata": {
        "id": "n-VHTXETi5_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_pokemon_list = all_pokemon_query[:]\n",
        "print(type(all_pokemon_list))\n",
        "print(type(all_pokemon_list[0]))\n",
        "print(f\"Name: {all_pokemon_list[0].name}, height: {all_pokemon_list[0].height}\")\n",
        "print(all_pokemon_list[0].to_dict())"
      ],
      "metadata": {
        "id": "CpdoozBRnZss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `.to_dict()` method on the `Entity` class converts the instance of the `Pokemon` class to a regular Python dictionary, meaning it’s pretty straightforward to now just feed everything into pandas with one line of code:"
      ],
      "metadata": {
        "id": "fZuEyH_0p0V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon_df = pd.DataFrame([pokemon.to_dict() for \n",
        "  pokemon in orm.select(p for p in Pokemon)[:]])\n",
        "pokemon_df.describe()"
      ],
      "metadata": {
        "id": "hDqB5P4S9q3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whether this is appropriate or not depends on your specific use case, but let’s start the db anew with a more thorough mapping of those fourteen tables, so we can leverage the relationality in the data."
      ],
      "metadata": {
        "id": "zFty8Z0YXWEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = orm.Database()\n",
        "db.bind(provider='sqlite', filename=\"/content/pokemon.sqlite\", create_db=False)\n",
        "\n",
        "class Pokemon(db.Entity):\n",
        "  id = orm.PrimaryKey(int, column=\"pok_id\", auto=True)\n",
        "  name = orm.Required(str, column=\"pok_name\")\n",
        "  height = orm.Optional(int, column=\"pok_height\")\n",
        "  weight = orm.Optional(int, column=\"pok_weight\")\n",
        "  base_experience = orm.Optional(int, column=\"pok_base_experience\")\n",
        "  base_stats = orm.Optional(\"BaseStat\")\n",
        "  moves = orm.Set(\"Move\", table=\"pokemon_moves\", column=\"move_id\")\n",
        "  abilities = orm.Set(\"Ability\", table=\"pokemon_abilities\", column=\"abil_id\")\n",
        "  habitats = orm.Set(\"Habitat\", column=\"hab_id\", table=\"pokemon_evolution_matchup\")\n",
        "  types = orm.Set(\"Type\", column=\"type_id\", table=\"pokemon_types\")\n",
        "\n",
        "class BaseStat(db.Entity):\n",
        "  _table_ = \"base_stats\"\n",
        "  hp = orm.Optional(int, column=\"b_hp\")\n",
        "  attack = orm.Optional(int, column=\"b_atk\")\n",
        "  defense = orm.Optional(int, column=\"b_def\")\n",
        "  special_attack = orm.Optional(int, column=\"b_sp_atk\")\n",
        "  special_defense = orm.Optional(int, column=\"b_sp_def\")\n",
        "  speed = orm.Optional(int, column=\"b_speed\")\n",
        "  pokemon = orm.PrimaryKey(Pokemon, column=\"pok_id\")  \n",
        "  \n",
        "class Ability(db.Entity):\n",
        "  _table_ = \"abilities\"\n",
        "  id = orm.PrimaryKey(int, column=\"abil_id\")\n",
        "  name = orm.Required(str, column=\"abil_name\")\n",
        "  pokemon = orm.Set(Pokemon, column=\"pok_id\", table=\"pokemon_abilities\")\n",
        " \n",
        "class Move(db.Entity):\n",
        "  _table_ = \"moves\"\n",
        "  id = orm.PrimaryKey(int, column=\"move_id\")\n",
        "  name = orm.Required(str, column=\"move_name\")\n",
        "  power = orm.Optional(int, column=\"move_power\") \n",
        "  pp = orm.Optional(int, column=\"move_pp\") \n",
        "  accuracy = orm.Optional(int, column=\"move_accuracy\")\n",
        "  pokemon = orm.Set(Pokemon, column=\"pok_id\", table=\"pokemon_moves\")\n",
        "\n",
        "class Habitat(db.Entity):\n",
        "  _table_ = \"pokemon_habitats\"\n",
        "  id = orm.PrimaryKey(int, column=\"hab_id\")\n",
        "  name = orm.Optional(str, column=\"hab_name\")\n",
        "  description = orm.Optional(str, column=\"hab_descript\")\n",
        "  pokemon = orm.Set(Pokemon, column=\"pok_id\", table=\"pokemon_evolution_matchup\")\n",
        "\n",
        "class Type(db.Entity):\n",
        "  _table_ = \"types\"\n",
        "  id = orm.PrimaryKey(int, column=\"type_id\")\n",
        "  name = orm.Required(str, column=\"type_name\")\n",
        "  pokemon = orm.Set(Pokemon, column=\"pok_id\", table=\"pokemon_types\")\n",
        "\n",
        "db.generate_mapping(check_tables=True, create_tables=False)"
      ],
      "metadata": {
        "id": "MpuR1i4YB6XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the tables mapped to Python objects, we can reproduce the query from above, seeing a list of Pokémon with attack, defense, and hp greater than 100. Because the base stats are stored in another table (`base_stats`) and get loaded via a relationship to it, we can’t rely simply on the `.to_dict()` method anymore and have to be more explicit."
      ],
      "metadata": {
        "id": "y5OrUE1R6qMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_base_stat_dict(pokemon):\n",
        "  return {\n",
        "    \"id\": pokemon.id,\n",
        "    \"name\": pokemon.name,\n",
        "    \"attack\": pokemon.base_stats.attack,\n",
        "    \"defense\": pokemon.base_stats.defense,\n",
        "    \"hp\": pokemon.base_stats.hp,\n",
        "    \"speed\": pokemon.base_stats.speed,\n",
        "    \"special_attack\": pokemon.base_stats.special_attack,\n",
        "    \"special_defense\": pokemon.base_stats.special_defense\n",
        "  }\n",
        "\n",
        "strong_pokemon = pd.DataFrame([ to_base_stat_dict(pokemon) for pokemon in \n",
        "                                Pokemon.select(lambda p: \n",
        "                                  p.base_stats.attack > 100 and \n",
        "                                  p.base_stats.defense > 100 and \n",
        "                                  p.base_stats.hp > 100)[:]\n",
        "                              ])\n",
        "strong_pokemon"
      ],
      "metadata": {
        "id": "zVDHKp4m_Xcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s implement a few other functions, etc., based on what Radomski and Allen provided in their [class report](https://github.com/columbia-data-club/Pokemon-Database/blob/master/Database%20Project.docx). For example, we can create a function that grabs a pokémon’s abilities and moves based on their name."
      ],
      "metadata": {
        "id": "SsE_ZgXKSxyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_abilities(pokemon_name):\n",
        "  pokemon = Pokemon.get(name=pokemon_name);\n",
        "  return pokemon.abilities\n",
        "\n",
        "def get_moves(pokemon_name):\n",
        "  pokemon = Pokemon.get(name=pokemon_name);\n",
        "  return pokemon.moves  \n",
        "\n",
        "pokemon_name = \"pikachu\"\n",
        "abilities = get_abilities(pokemon_name)\n",
        "print(f\"### Abilities for {pokemon_name}:\")\n",
        "for ability in abilities:\n",
        "  print(ability.name)\n",
        "\n",
        "pokemon_name = \"venusaur\"\n",
        "moves = get_moves(pokemon_name)\n",
        "print(f\"### Moves for {pokemon_name}:\")\n",
        "for move in moves:\n",
        "  print(move.name)"
      ],
      "metadata": {
        "id": "MB-pmSIwSxGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can grab all the Pokémon who live in a certain habitat."
      ],
      "metadata": {
        "id": "S74hEufB3jqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cave = Habitat.get(name=\"cave\")\n",
        "for pokemon in cave.pokemon:\n",
        "  print(pokemon.name)"
      ],
      "metadata": {
        "id": "hxzP_iYm12hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don’t know much about pokémon, but I find it curious that a pokémon can have more than one type, at least that’s how the database is designed:\n",
        "\n",
        "```python\n",
        "class Pokemon(db.Entity):\n",
        "# ...\n",
        "  types = orm.Set(\"Type\", column=\"type_id\", table=\"pokemon_types\")\n",
        "\n",
        "class Type(db.Entity):\n",
        "# ...\n",
        "  pokemon = orm.Set(Pokemon, column=\"pok_id\", table=\"pokemon_types\")\n",
        "  ```\n",
        "\n",
        "  Are there pokémon with more than one type?"
      ],
      "metadata": {
        "id": "-1QqjmhK3qcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Pokemon.select(lambda p: orm.count(p.types) > 1).count())\n",
        "\n",
        "#pokemon = Pokemon.select(lambda p: orm.count(p.types) > 1).random(1)[:][0]\n",
        "#print(f\"{pokemon.name.capitalize()} is a multi-type pokémon: {[type.name for type in pokemon.types]}\")"
      ],
      "metadata": {
        "id": "zWnnF3cYM16d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And so on. We can continue playing these sorts of queries, etc., forever, but you can see now how to link up your notebook to a SQL database and, what’s more, how to leverage Pythonic generators and list comprehensions to query a database. \n",
        "\n",
        "You’ve also seen that flattening the relations in a database to a dataframe is possible, but not necessarily preferable. For example, adding the pokémon’s habitat to the dataframe of base stats is rather trivial, but how do we account for the fact that each pokémon has more than one ability? Or many moves? Or even many types? How do we account for that diversity in the two-dimensional space of a dataframe?\n",
        "\n",
        "These questions have no real, correct answer; the solution depends on what the next steps are. For example, _internally_, the way the database keeps a many-to-many relationship straight is by using an intermediary table of ids from each table, thereby creating something that resembles what Hadley Wickham calls “[tidy data](http://vita.had.co.nz/papers/tidy-data.pdf),” where every row in the intermediate column is an observation on the nature of a relationship between a pokémon and a type. Hence, our dataframe could have a column, `type`, that then occasions the same pokémon appearing multiple times among the rows. Or each row could be a type, repeating as necessary to account for all the pokémon, who makeup a column. \n",
        "\n",
        "Structural questions like these, of course, are part of why relational databases exist in the first place! If each entity has its own properties attached to itself, and its relationships are clearly defined, then it should be the case that we can create any sort of dataframe that smushes those relationships into two dimensions, depending on what we need."
      ],
      "metadata": {
        "id": "Rvs0eEoA5r_N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z5m1BnNQ8ZBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}